{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from qiskit.quantum_info import Statevector\n",
    "import numpy as np\n",
    "from qiskit import Aer, QuantumCircuit, execute\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics.pairwise import rbf_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIC FUNCTIONS AND FIDELITY_SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione per fit dentro fidelity_per_site\n",
    "def exp_func(x, a, b):\n",
    "    return a * np.exp(b*x)\n",
    "\n",
    "# per kernel classico\n",
    "def rbf_func(x1,x2, circuit, gamma = 0.05):\n",
    "    #assert len(x1)==len(x2)\n",
    "    distance_squared = np.sum((x1 - x2) ** 2)\n",
    "    kernel_value = np.exp(-gamma * distance_squared)\n",
    "    return kernel_value\n",
    "\n",
    "# fidelity tramite StateVector\n",
    "def fidelity_SV(x1,x2, circuit):\n",
    "    encoded_x_i = circuit.assign_parameters(x1)\n",
    "    encoded_x_j = circuit.assign_parameters(x2)\n",
    "    statevector_i = Statevector.from_instruction(encoded_x_i)\n",
    "    statevector_j = Statevector.from_instruction(encoded_x_j)\n",
    "    kernel_value = abs(statevector_j.conjugate().data @ statevector_i.data)**2\n",
    "    return kernel_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIDELITIES KERNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "# fidelity tramite QuasmSimulator\n",
    "def fidelity(x1, x2,  circuit, shots=1000):\n",
    "    assert len(x1) == len(x2)\n",
    "    n = len(x1)\n",
    "    encoded_x_i = circuit.assign_parameters(x1)\n",
    "    encoded_x_j = circuit.assign_parameters(x2)\n",
    "    qc = QuantumCircuit(N, N)\n",
    "    qc.append(encoded_x_i, range(N))\n",
    "    qc.append(encoded_x_j.inverse(), range(N)) \n",
    "    qc.measure(range(N), range(N))\n",
    "    counts = execute(qc, backend, shots=shots).result().get_counts()\n",
    "\n",
    "    # calcolo della sovrapposzione tramite frequenza di outcome |0>\n",
    "    kernel_value = np.sqrt(counts.get('0' * N, 0) / shots)\n",
    "    return kernel_value\n",
    "\n",
    "# fidelity per sito (lambda)\n",
    "def fidelity_per_site(x1, x2,  circuit, n_start=1, reps=4, shots=2000):\n",
    "    assert len(x1) == len(x2)\n",
    "    n_meas=n_start\n",
    "    encoded_x_i = circuit.assign_parameters(x1)\n",
    "    encoded_x_j = circuit.assign_parameters(x2)\n",
    "    p_0=[]\n",
    "    Ns_meas = []\n",
    "\n",
    "    for _ in range(reps):\n",
    "        n_meas += 1\n",
    "        Ns_meas.append(n_meas)\n",
    "\n",
    "        # varia il numero di qubit misurati ogni volta\n",
    "        qc = QuantumCircuit(N, n_meas)\n",
    "        qc.append(encoded_x_i, range(N))\n",
    "        qc.append(encoded_x_j.inverse(), range(N)) \n",
    "        qc.measure(range(n_meas), range(n_meas))\n",
    "\n",
    "        # misura della sovrapposzione, limitata nel numero di qubit\n",
    "        counts = execute(qc, backend, shots=shots).result().get_counts()\n",
    "        p_0.append(counts.get('0' * n_meas, 0) / shots)\n",
    "    p_0 = np.array(p_0)\n",
    "    Ns_meas = np.array(Ns_meas)\n",
    "\n",
    "    # fit per determinare lambda(n) n: numero di bit, ed estrapolare Lambda(N) N grande\n",
    "    popt, pcov = curve_fit(exp_func, Ns_meas, p_0)\n",
    "    kernel_value = exp_func(N, *popt)**(1/(2*N))\n",
    "    return kernel_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOISY FIDELITY KERNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_aer.primitives import Sampler\n",
    "from qiskit_aer.noise import NoiseModel, depolarizing_error\n",
    "from qiskit.result import  ProbDistribution\n",
    "\n",
    "\n",
    "# metodi di error mitigation, non eseguiti per ragioni di tempo computazionale troppo elevato\n",
    "\"\"\"from qiskit_ibm_runtime import QiskitRuntimeService, Sampler, Options\n",
    "service=QiskitRuntimeService()\n",
    "options = Options()\n",
    "options.resilience_level = 1\n",
    "options.optimization_level = 3\n",
    "backend = service.backend(\"ibmq_qasm_simulator\")\n",
    "sampler = Sampler(options=options, backend = backend)\"\"\"\n",
    "\n",
    "# errore di decoerenza nei gate CNOT, con probabilità variabile\n",
    "noise_model = NoiseModel()\n",
    "cx_depolarizing_prob = 0.1\n",
    "noise_model.add_all_qubit_quantum_error(depolarizing_error(cx_depolarizing_prob, 2), [\"cx\"])\n",
    "sampler = Sampler(backend_options={\"noise_model\": noise_model})\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# fidelity col sampler, utilizzata per ragioni di migliore compatibilità nel caso di rumore\n",
    "\n",
    "# equivalente a quella con QuasmSimulator\n",
    "def fidelity_sampler(x1, x2,  circuit, shots=1000):\n",
    "    assert len(x1) == len(x2)\n",
    "    encoded_x_i = circuit.assign_parameters(x1)\n",
    "    encoded_x_j = circuit.assign_parameters(x2)\n",
    "    qc = QuantumCircuit(N, N)\n",
    "    qc.append(encoded_x_i, range(N))\n",
    "    qc.append(encoded_x_j.inverse(), range(N)) \n",
    "    qc.measure(range(N), range(N))\n",
    "    job=sampler.run(qc, shots=shots)\n",
    "    result = job.result()\n",
    "    quasi_dist=result.quasi_dists[0]\n",
    "    if 0 in quasi_dist:\n",
    "        kernel_value =np.sqrt(abs(quasi_dist[0]))\n",
    "    else:\n",
    "        kernel_value=0\n",
    "    return kernel_value\n",
    "\n",
    "# alternativa equivalente suggerita nella documentazione Qiskit\n",
    "def fidelity_sampler_bis(x1, x2, circuit, shots=1000):\n",
    "    qc1 = circuit.assign_parameters(x1)\n",
    "    qc2 = circuit.assign_parameters(x2)\n",
    "    qc1.measure_all()\n",
    "    qc2.measure_all()\n",
    "    job1 = sampler.run(qc1, shots= shots)\n",
    "    job2 = sampler.run(qc2, shots= shots)\n",
    "    quasis1 = job1.result().quasi_dists[0]\n",
    "    quasis2 = job2.result().quasi_dists[0]\n",
    "    dist1 = quasis1.nearest_probability_distribution()\n",
    "    dist2 = quasis2.nearest_probability_distribution()\n",
    "    result=0\n",
    "    for bitstring in dist1 | dist2:\n",
    "        prob1 = dist1.get(bitstring, 0)\n",
    "        prob2 = dist2.get(bitstring, 0)\n",
    "        result += np.sqrt(prob1*prob2)\n",
    "    return result**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "\n",
    "    def __init__(self,N_spins):\n",
    "        self.N_spins = N_spins\n",
    "        self.circuit = RealAmplitudes(num_qubits=N_spins, reps=3)\n",
    "        self.data = None\n",
    "        self.N_dataset = None\n",
    "        self.J_alldata = None\n",
    "        self.parameters_alldata = None\n",
    "        self.trainset_size = None\n",
    "        self.data_train = None\n",
    "        self.parameters_train = None\n",
    "        self.J_train = None\n",
    "        self.distance = None\n",
    "        self.k_matrix = None\n",
    "        self.SVM = SVC(kernel='precomputed')\n",
    "        self.y = None\n",
    "        self.dual_coeff = None\n",
    "        self.support_vectors = None\n",
    "        self.accuracy = None\n",
    "        self.J_test = None\n",
    "        self.test_data = None\n",
    "        self.test_parameters = None\n",
    "        self.test_size = 200\n",
    "        self.smoothed_distance = None\n",
    "        self.smoothed_J_test = None\n",
    "        \n",
    "\n",
    "    def initialize(self, data_file = 'dataset/dataset_nuovo_600.csv', trainset_size=100, training_set= 'delta'):\n",
    "        self.trainset_size = trainset_size\n",
    "        data = pd.read_csv(data_file)\n",
    "        self.data = np.array(data)\n",
    "        self.J_alldata = self.data[:,0]\n",
    "        self.parameters_alldata = self.data[:,3:]\n",
    "        self.N_dataset = len(self.data)\n",
    "        if training_set=='delta':\n",
    "            indici = np.random.choice(self.N_dataset, size=trainset_size, replace=False); indici.sort()\n",
    "        elif training_set=='sigma_1':\n",
    "            indici1 = np.arange(201, 251)\n",
    "            indici2 = np.arange(350, 400)\n",
    "            indici = np.concatenate((indici1,indici2))\n",
    "        elif training_set=='sigma_2':\n",
    "            indici1 = np.arange(151, 201)\n",
    "            indici2 = np.arange(400, 450)\n",
    "            indici = np.concatenate((indici1,indici2))\n",
    "        elif training_set=='sigma_3':\n",
    "            indici1 = np.range(219,261)\n",
    "            indici2 = np.range(540,583)\n",
    "            indici = np.concatenate((indici1,indici2))\n",
    "        else:\n",
    "            print(\"Intervallo per il trainset non riconosciuto\")\n",
    "        self.train_data = self.data[indici, :]\n",
    "        self.train_parameters = self.train_data[:,3:]\n",
    "        self.J_train = self.train_data[:,0]\n",
    "        self.y = np.where(self.J_train.astype(float)<1,-1,1)\n",
    "        self.test_data = self.data[200:400, :]\n",
    "        self.J_test = self.test_data[:,0]\n",
    "        self.test_parameters = self.test_data[:,3:]\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "    # calcolo della matrice dei kernel, con funzione di kernel variabile\n",
    "    def kernel_matrix_construct(self, kernel_func, save = True, save_file='kernel_matrix'):\n",
    "        k_matr = np.zeros(shape=(self.trainset_size,self.trainset_size))\n",
    "        for i in range(self.trainset_size):\n",
    "            print(f'Calcolo kernel, riga numero={i}', end='\\r')\n",
    "            x1 = self.train_parameters[i,:]\n",
    "            # si calcola solamente la matrice triangolare inferiore: il risultato deve essere simmetrico\n",
    "            for j in range(i):\n",
    "                x2 = self.train_parameters[j,:]\n",
    "                k_matr[i,j] = kernel_func(x1,x2,circuit = self.circuit)\n",
    "        \n",
    "        # simmetrizzazione della matrice ed aggiunta degli 1 sulla diagonale\n",
    "        k_matr_simmetrized = k_matr + k_matr.transpose() + np.diag(np.ones(self.trainset_size))\n",
    "        self.k_matrix = k_matr_simmetrized\n",
    "        if save:\n",
    "            np.savetxt(save_file + '.txt', k_matr_simmetrized)\n",
    "            np.save(save_file + '.npy', k_matr_simmetrized)\n",
    "\n",
    "    def kernel_matrix_plot(self):\n",
    "        plt.imshow(self.k_matrix, origin='lower')\n",
    "        plt.title(\"Kernel matrix\")\n",
    "        xx = np.linspace(0,99,5).astype(int)\n",
    "        jj = np.round(self.J_train[xx],2)\n",
    "        plt.xticks(xx,jj); plt.yticks(xx,jj)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    # calcolo della SVM, accuratezza ed indici dei vettori di supporto\n",
    "    def driver_SVM(self):\n",
    "        self.SVM.fit(self.k_matrix, self.y)\n",
    "        prediction=self.SVM.predict(self.k_matrix)\n",
    "        correct = np.sum(self.y == prediction)\n",
    "        self.accuracy = correct / len(self.y)\n",
    "\n",
    "        # coefficienti nel calcolo delle distante relativi ai vettori di support\n",
    "        self.dual_coeff = self.SVM.dual_coef_\n",
    "\n",
    "        # indici dei vettori di supporto (nel training set) che ritronano coefficienti non nulli \n",
    "        self.support_vectors = self.SVM.support_\n",
    "        print(f'Accuracy of the SVM = {self.accuracy}')\n",
    "        print(f'Offset parameter b= {self.SVM.intercept_}')\n",
    "\n",
    "    # calcolo di d(J)\n",
    "    def distance_calc(self, kernel_func, save=True, save_file = 'distances'):\n",
    "        self.distance = np.zeros(self.test_size)\n",
    "        print(\"---------------------------\")\n",
    "        # la distanza si può calcolare per J qualsiasi\n",
    "        for i in range(self.test_size):\n",
    "            print(f'Calcolo distance, riga numero={i}',end='\\r')\n",
    "            x1 = self.test_parameters[i,:]\n",
    "\n",
    "            # ma all'interno della formula, il secondo indice del kernel corrisponde ai vettori di supporto\n",
    "            for num_j,j in enumerate(self.support_vectors):\n",
    "                x2=self.train_parameters[j,:]\n",
    "                self.distance[i] += self.dual_coeff[0,num_j]*kernel_func(x1,x2,circuit=self.circuit)\n",
    "        self.distance += self.SVM.intercept_\n",
    "        print(\"---------------------------\")\n",
    "        if save:\n",
    "            np.save(save_file, self.distance)\n",
    "        \n",
    "        # per rendere il risultato più pulito, la funzione distanza viene \"levigata\" tramite coarse graining\n",
    "        self.smoothed_distance = np.convolve(self.distance, np.ones(20)/20, mode='valid')\n",
    "        self.smoothed_J_test= np.convolve(self.J_test, np.ones(20)/20, mode='valid')\n",
    "        if save:\n",
    "            np.save('sm_' + save_file + 'npy', self.smoothed_distance)\n",
    "\n",
    "        # e J_c calcolata come l'intersizione delle distanze con 0\n",
    "        print(f'J_phase_transition = {self.J_test[abs(self.distance).argmin()]}',\n",
    "              f'dist_min = {abs(self.distance[abs(self.distance).argmin()])}')\n",
    "        print(f'smoothed_J_phase_transition = {self.smoothed_J_test[abs(self.smoothed_distance).argmin()]}',\n",
    "              f'smoothed_dist_min = {abs(self.smoothed_distance[abs(self.smoothed_distance).argmin()])}')\n",
    "\n",
    "    def distance_plot(self):\n",
    "        plt.plot(self.J_test,self.distance, label = 'Distance')\n",
    "        plt.plot((self.smoothed_J_test),self.smoothed_distance, label='Coarse grained distance')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 SPIN CHAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel classico su 10 spin\n",
    "N=10\n",
    "chain_10_rbf = Model(N)\n",
    "chain_10_rbf.initialize()\n",
    "chain_10_rbf.k_matrix = rbf_kernel(chain_10_rbf.train_parameters,gamma=0.05)\n",
    "chain_10_rbf.kernel_matrix_plot()\n",
    "chain_10_rbf.driver_SVM()\n",
    "chain_10_rbf.distance_calc(rbf_func, save=False)\n",
    "chain_10_rbf.distance_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fidelities w noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel fidelity + rumore (impsotabile su 0)\n",
    "# il caso di fidelity per sito è stato eseguito analogamente, \n",
    "# basta variare le funzioni in ingresso a kernel_matrix_construct e distance_calc\n",
    "\n",
    "N=10\n",
    "chain_10_fidelity = Model(N)\n",
    "chain_10_fidelity.initialize()\n",
    "chain_10_fidelity.kernel_matrix_construct(fidelity, save_file='fidelity_simul')\n",
    "chain_10_fidelity.kernel_matrix_plot()\n",
    "chain_10_fidelity.driver_SVM()\n",
    "chain_10_fidelity.distance_calc(fidelity, save_file='distances_simul')\n",
    "chain_10_fidelity.distance_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10\n",
    "chain_10_fidelity_SV = Model(N)\n",
    "chain_10_fidelity_SV.initialize()\n",
    "chain_10_fidelity_SV.kernel_matrix_construct(fidelity_sampler, save_file='ourfidelity_sampler_10s_1000s_k')\n",
    "chain_10_fidelity_SV.kernel_matrix_plot()\n",
    "chain_10_fidelity_SV.driver_SVM()\n",
    "chain_10_fidelity_SV.distance_calc(fidelity_sampler, save_file='ourfidelity_sampler_10s_1000s_d')\n",
    "chain_10_fidelity_SV.distance_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 SPIN CHAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5\n",
    "gamma=2.5\n",
    "prova0 = Model(N)\n",
    "prova0.initialize(data_file='dataset/dataset_5_spin.csv', training_set='delta')\n",
    "prova0.kernel_matrix_construct(lambda x1, x2, circuit: rbf_func(x1, x2, circuit=None, gamma=gamma))\n",
    "prova0.kernel_matrix_plot()\n",
    "prova0.driver_SVM()\n",
    "prova0.distance_calc(lambda x1, x2, circuit: rbf_func(x1, x2, circuit=None, gamma=gamma), save=False)\n",
    "prova0.distance_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fidelities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5\n",
    "gamma=2\n",
    "prova0 = Model(N)\n",
    "prova0.initialize(data_file='dataset/dataset_5_spin.csv', training_set='delta')\n",
    "prova0.kernel_matrix_construct(fidelity)\n",
    "prova0.kernel_matrix_plot()\n",
    "prova0.driver_SVM()\n",
    "prova0.distance_calc(fidelity)\n",
    "prova0.distance_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qubits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
